{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e15062e",
   "metadata": {},
   "source": [
    "# Multimodal Image Search Demo\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Basic search using CLIP\n",
    "2. Hybrid search using CLIP + BLIP-2 for better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba1394",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b972560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import Flickr30KDataset\n",
    "from src.encoder import CLIPEncoder\n",
    "from src.index import FAISSIndex\n",
    "from src.search import SearchEngine\n",
    "from src.reranker import BLIP2Reranker\n",
    "from src.hybrid_search import HybridSearchEngine\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ded6d",
   "metadata": {},
   "source": [
    "## Load Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c4a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = Flickr30KDataset('data/images', 'data/results.csv')\n",
    "\n",
    "# Load encoder\n",
    "encoder = CLIPEncoder()\n",
    "\n",
    "# Load indices\n",
    "image_index = FAISSIndex()\n",
    "image_index.load('data/image_index.faiss')\n",
    "\n",
    "text_index = FAISSIndex()\n",
    "text_index.load('data/text_index.faiss')\n",
    "\n",
    "# Create search engine\n",
    "engine = SearchEngine(encoder, image_index, text_index, dataset)\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cdedd1",
   "metadata": {},
   "source": [
    "## Text-to-Image Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1904d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for images\n",
    "query = \"a dog playing in the park\"\n",
    "results = engine.text_to_image(query, k=5)\n",
    "\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "for i, (img_name, score) in enumerate(results, 1):\n",
    "    print(f\"{i}. {img_name} (score: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09386a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i, (img_name, score) in enumerate(results):\n",
    "    img = dataset.get_image(img_name)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'{score:.3f}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d48fcb",
   "metadata": {},
   "source": [
    "## Image-to-Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb8360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use first result from above\n",
    "test_image = results[0][0]\n",
    "captions = engine.image_to_text(f'data/images/{test_image}', k=5)\n",
    "\n",
    "print(f\"Image: {test_image}\\n\")\n",
    "for i, (caption, score) in enumerate(captions, 1):\n",
    "    print(f\"{i}. {caption}\")\n",
    "    print(f\"   Score: {score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715e252",
   "metadata": {},
   "source": [
    "## Image-to-Image Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find similar images\n",
    "similar = engine.image_to_image(f'data/images/{test_image}', k=6)\n",
    "\n",
    "print(f\"Query image: {test_image}\\n\")\n",
    "for i, (img_name, score) in enumerate(similar, 1):\n",
    "    print(f\"{i}. {img_name} (score: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38d958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similar images\n",
    "fig, axes = plt.subplots(1, 6, figsize=(18, 3))\n",
    "for i, (img_name, score) in enumerate(similar):\n",
    "    img = dataset.get_image(img_name)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'{score:.3f}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5a4ca",
   "metadata": {},
   "source": [
    "## Hybrid Search (CLIP + BLIP-2)\n",
    "\n",
    "Hybrid search uses two stages:\n",
    "1. CLIP retrieves top 50 candidates (fast)\n",
    "2. BLIP-2 re-ranks them to find best 5 (accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d43ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BLIP-2 re-ranker\n",
    "print(\"Loading BLIP-2...\")\n",
    "reranker = BLIP2Reranker()\n",
    "\n",
    "# Create hybrid search engine\n",
    "hybrid_engine = HybridSearchEngine(encoder, image_index, dataset, reranker)\n",
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fe70d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare CLIP-only vs Hybrid search\n",
    "query = \"children playing soccer\"\n",
    "\n",
    "print(\"=== CLIP Only (single stage) ===\")\n",
    "clip_results = engine.text_to_image(query, k=5)\n",
    "for i, (img_name, score) in enumerate(clip_results, 1):\n",
    "    print(f\"{i}. {img_name} (score: {score:.4f})\")\n",
    "\n",
    "print(\"\\n=== Hybrid (CLIP + BLIP-2) ===\")\n",
    "hybrid_results = hybrid_engine.search(query, k1=50, k2=5)\n",
    "for i, (img_name, score) in enumerate(hybrid_results, 1):\n",
    "    print(f\"{i}. {img_name} (score: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3308f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "# Top row: CLIP results\n",
    "for i, (img_name, score) in enumerate(clip_results):\n",
    "    img = dataset.get_image(img_name)\n",
    "    axes[0, i].imshow(img)\n",
    "    axes[0, i].axis('off')\n",
    "    axes[0, i].set_title(f'CLIP: {score:.3f}')\n",
    "\n",
    "# Bottom row: Hybrid results  \n",
    "for i, (img_name, score) in enumerate(hybrid_results):\n",
    "    img = dataset.get_image(img_name)\n",
    "    axes[1, i].imshow(img)\n",
    "    axes[1, i].axis('off')\n",
    "    axes[1, i].set_title(f'Hybrid: {score:.3f}')\n",
    "\n",
    "plt.suptitle(f\"Query: '{query}'\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71c0e05",
   "metadata": {},
   "source": [
    "## Try Your Own Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17bdf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to test different queries\n",
    "my_query = \"a black dog running\"\n",
    "\n",
    "results = hybrid_engine.search(my_query, k1=100, k2=5)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i, (img_name, score) in enumerate(results):\n",
    "    img = dataset.get_image(img_name)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'{score:.3f}')\n",
    "plt.suptitle(f\"Hybrid Search: '{my_query}'\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
