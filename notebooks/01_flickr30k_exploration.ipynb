{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e925fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAGGLE SETUP - Cell 1: Clone repository and install dependencies\n",
    "!rm -rf hybrid_multimodal_retrieval\n",
    "!git clone https://github.com/vinhhna/hybrid_multimodal_retrieval.git\n",
    "%cd hybrid_multimodal_retrieval\n",
    "!pip install -q transformers accelerate open-clip-torch pyyaml tqdm pillow faiss-cpu\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b11c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAGGLE SETUP - Cell 2: Setup data paths\n",
    "from pathlib import Path\n",
    "\n",
    "# Set paths based on Kaggle dataset location\n",
    "IMAGES_DIR = Path('/kaggle/input/flickr30k/data/images')\n",
    "CAPTIONS_FILE = Path('/kaggle/input/flickr30k/data/results.csv')\n",
    "\n",
    "# Verify paths\n",
    "print(f\"Images dir exists: {IMAGES_DIR.exists()} - {IMAGES_DIR}\")\n",
    "print(f\"Captions file exists: {CAPTIONS_FILE.exists()} - {CAPTIONS_FILE}\")\n",
    "\n",
    "if IMAGES_DIR.exists():\n",
    "    num_images = len(list(IMAGES_DIR.glob('*.jpg')))\n",
    "    print(f\"Found {num_images} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36b5f4c",
   "metadata": {},
   "source": [
    "## ðŸš€ Kaggle Setup - RUN THESE FIRST!\n",
    "\n",
    "**Important:** Execute the two cells above before proceeding with the rest of the notebook.\n",
    "\n",
    "These cells will:\n",
    "1. Clone the repository and install all dependencies\n",
    "2. Set up the correct data paths for Kaggle environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10949e83",
   "metadata": {},
   "source": [
    "# Flickr30K Dataset Exploration\n",
    "\n",
    "This notebook provides exploration and analysis of the Flickr30K dataset for hybrid multimodal retrieval.\n",
    "\n",
    "**For Kaggle:** Run the setup cells at the top first!\n",
    "\n",
    "## Dataset Information\n",
    "- **Images**: 31,000 images from Flickr\n",
    "- **Captions**: 5 captions per image (~158,915 total)\n",
    "- **Format**: CSV file with pipe-delimited captions, JPEG images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1982b45c",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3543f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our flickr30k package (installed via setup cells)\n",
    "from flickr30k import Flickr30KDataset\n",
    "from flickr30k.visualization import (\n",
    "    display_image_with_captions,\n",
    "    display_random_samples,\n",
    "    plot_caption_statistics,\n",
    "    print_dataset_statistics,\n",
    "    display_search_results\n",
    ")\n",
    "from flickr30k.utils import (\n",
    "    load_config,\n",
    "    print_data_status,\n",
    "    check_data_availability\n",
    ")\n",
    "\n",
    "print(\"âœ“ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5edf3fd",
   "metadata": {},
   "source": [
    "## 2. Check Dataset Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ec116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if dataset is available\n",
    "print_data_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694f73ae",
   "metadata": {},
   "source": [
    "## 3. Verify Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249fccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Kaggle data paths (set in setup cells above)\n",
    "print(\"Using Kaggle data paths:\")\n",
    "print(f\"  Images directory: {IMAGES_DIR}\")\n",
    "print(f\"  Captions file: {CAPTIONS_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e25c4",
   "metadata": {},
   "source": [
    "## 4. Initialize and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb02f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset with Kaggle paths\n",
    "dataset = Flickr30KDataset(\n",
    "    images_dir=str(IMAGES_DIR),\n",
    "    captions_file=str(CAPTIONS_FILE),\n",
    "    auto_load=True\n",
    ")\n",
    "\n",
    "print(f\"\\n{dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ef1d6",
   "metadata": {},
   "source": [
    "## 5. Verify Caption Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a676f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample captions for first image\n",
    "unique_images = dataset.get_unique_images()\n",
    "first_image = unique_images[0]\n",
    "\n",
    "print(f\"Sample captions for '{first_image}':\")\n",
    "captions = dataset.get_captions(first_image)\n",
    "for i, caption in enumerate(captions, 1):\n",
    "    print(f\"{i}. {caption}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f643c",
   "metadata": {},
   "source": [
    "## 6. Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245346c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comprehensive statistics\n",
    "print_dataset_statistics(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb46eba",
   "metadata": {},
   "source": [
    "## 7. Visualize Caption Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d1dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot caption length distributions\n",
    "plot_caption_statistics(dataset, figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33962a7",
   "metadata": {},
   "source": [
    "## 8. Display Random Sample Images with Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab7863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 3 random samples\n",
    "display_random_samples(\n",
    "    dataset=dataset,\n",
    "    n_samples=3,\n",
    "    seed=42,\n",
    "    figsize=(10, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb31b192",
   "metadata": {},
   "source": [
    "## 9. Display Specific Image with Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f050e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a specific image\n",
    "# Change the image name to view different images\n",
    "image_name = unique_images[10]  # Change index to view different images\n",
    "\n",
    "display_image_with_captions(\n",
    "    image_name=image_name,\n",
    "    dataset=dataset,\n",
    "    figsize=(10, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef01af5",
   "metadata": {},
   "source": [
    "## 10. Analyze Caption Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9872e86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check caption uniqueness\n",
    "unique_captions = dataset.df['caption'].nunique()\n",
    "total_captions = len(dataset.df)\n",
    "duplicate_ratio = 1 - (unique_captions / total_captions)\n",
    "\n",
    "print(f\"Total captions: {total_captions:,}\")\n",
    "print(f\"Unique captions: {unique_captions:,}\")\n",
    "print(f\"Duplicate ratio: {duplicate_ratio:.4f} ({duplicate_ratio*100:.2f}%)\")\n",
    "\n",
    "# Find most common captions\n",
    "print(\"\\nTop 10 Most Common Captions:\")\n",
    "caption_counts = dataset.df['caption'].value_counts().head(10)\n",
    "for caption, count in caption_counts.items():\n",
    "    print(f\"  [{count}x] {caption[:80]}{'...' if len(caption) > 80 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d95382d",
   "metadata": {},
   "source": [
    "## 11. Search Captions by Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for captions containing a keyword\n",
    "keyword = \"dog\"  # Change this to search for different keywords\n",
    "\n",
    "results = dataset.search_captions(keyword, max_results=10)\n",
    "display_search_results(\n",
    "    results_df=results,\n",
    "    keyword=keyword,\n",
    "    max_display=5,\n",
    "    show_images=False,  # Set to True to show images (slower)\n",
    "    dataset=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96b25e",
   "metadata": {},
   "source": [
    "## 12. Interactive Exploration\n",
    "\n",
    "Use the cells below to explore the dataset interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedeadcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random sample\n",
    "image_name, captions = dataset.get_random_sample(seed=None)\n",
    "\n",
    "print(f\"Random image: {image_name}\")\n",
    "print(\"\\nCaptions:\")\n",
    "for i, caption in enumerate(captions, 1):\n",
    "    print(f\"{i}. {caption}\")\n",
    "\n",
    "# Display the image\n",
    "display_image_with_captions(image_name, dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efb4b47",
   "metadata": {},
   "source": [
    "## 13. Export Sample Data\n",
    "\n",
    "Export a subset of data for further analysis or experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ba4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample subset (e.g., 1000 images)\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "sample_images = np.random.choice(unique_images, size=1000, replace=False)\n",
    "sample_df = dataset.df[dataset.df['image_name'].isin(sample_images)]\n",
    "\n",
    "print(f\"Sample subset created:\")\n",
    "print(f\"  Images: {len(sample_images)}\")\n",
    "print(f\"  Captions: {len(sample_df)}\")\n",
    "\n",
    "# Optionally save to CSV\n",
    "# sample_df.to_csv('data/flickr30k_sample_1k.csv', index=False)\n",
    "# print(\"âœ“ Sample saved to data/flickr30k_sample_1k.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5826f4da",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've explored the dataset, here are some next steps:\n",
    "\n",
    "1. **Feature Extraction**: Extract visual features using pre-trained models (ResNet, CLIP)\n",
    "2. **Text Embedding**: Create embeddings for captions using transformers\n",
    "3. **Hybrid Retrieval**: Implement text-to-image and image-to-text search\n",
    "4. **Evaluation**: Implement retrieval metrics (Recall@K, MRR, MAP)\n",
    "5. **Model Training**: Fine-tune models for better cross-modal alignment\n",
    "\n",
    "Check the project README for more information on the roadmap!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
